version: "3.8"

services:
  # API Gateway - Custom Gateway thay tháº¿ Kong
  api-gateway:
    build:
      context: .
      dockerfile: ./api-gateway/Dockerfile.dev
    ports:
      - "8080:8080"
    env_file:
      - ./api-gateway/.env
    volumes:
      - ./api-gateway:/app/api-gateway:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    depends_on:
      - auth-service
      - product-service
      - cart-service
      - order-service
      - search-service
    networks:
      - default    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]

  auth-service:
    build:
      context: .
      dockerfile: ./auth-service/Dockerfile.dev
    ports:
      - "8081:8081"
    env_file:
      - ./auth-service/.env
    volumes:
      - ./auth-service:/app/auth-service:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    depends_on:
      - postgres-auth
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"  
    command: ["air", "-c", ".air.toml"]

  user-service: 
    build:
      context: .
      dockerfile: ./user-service/Dockerfile.dev
    ports:
      - "8085:8085"
      - "8095:8095"
    env_file:
      - ./user-service/.env
    volumes:
      - ./user-service:/app/user-service:cached
      - ./module:/app/module:cached
    depends_on:
      - kafka
      - postgres-user
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"  
    command: ["air", "-c", ".air.toml"]
  product-service:
    build:
      context: .
      dockerfile: ./product-service/Dockerfile.dev
    ports:
      - "8082:8082"
    env_file:
      - ./product-service/.env
    volumes:
      - ./product-service:/app/product-service:cached
      - ./module:/app/module:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
      # Mount uploads directory for file handling
      - ./product-service/uploads:/app/product-service/uploads
    depends_on:
      - kafka
      - redis
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
  cart-service:
    build:
      context: .
      dockerfile: ./cart-service/Dockerfile.dev
    ports:
      - "8083:8083"
      - "8090:8090"
    env_file:
      - ./cart-service/.env
    volumes:
      - ./cart-service:/app/cart-service:cached
      - ./module:/app/module:cached
      # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    depends_on:
      - kafka
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
  order-service:
    build:
      context: .
      dockerfile: ./order-service/Dockerfile.dev
    ports:
      - "8084:8084"
    env_file:
      - ./order-service/.env
    volumes:
      - ./order-service:/app/order-service:cached
      - ./module:/app/module:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    depends_on:
      - kafka
      - postgres-order
  # Database variables are provided via env files (./order-service/.env and ./.env)
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
  search-service:
    build:
      context: .
      dockerfile: ./search-service/Dockerfile.dev
    ports:
      - "8086:8086"
    env_file:
      - ./search-service/.env
    volumes:
      - ./search-service:/app/search-service:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    depends_on:
      - kafka
      - elasticsearch
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
  email-service:
    build:
      context: .
      dockerfile: ./email-service/Dockerfile.dev
    env_file:
      - ./email-service/.env
    ports:
      - "8087:8087"
    volumes:
      - ./email-service:/app/email-service:cached
 # - ./go.mod:/app/go.mod:ro
      # - ./go.sum:/app/go.sum:ro
    networks:
      - default
    command: ["air", "-c", ".air.toml"]
  
  review-service:
    build:
      context: .
      dockerfile: ./review-service/Dockerfile.dev
    container_name: review-service
    ports:
      - "8089:8089"
    env_file:
      - ./review-service/.env
    volumes:
      - ./review-service:/app/review-service:cached
    depends_on:
      - kafka
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
  payment-service:
    build:
      context: .
      dockerfile: ./payment-service/dockerfile.dev
    ports:
      - "8088:8088"
    depends_on:
      - postgres-payment
    env_file:
      - ./.env
    environment:
      # Non-DB variables remain; DB variables are loaded from ./.env or service env file
      WEBHOOK_SECRET: ${WEBHOOK_SECRET}
      PORT: ${PORT}
      PAYMENT_GATEWAY_URL: ${PAYMENT_GATEWAY_URL}
      PAYMENT_GATEWAY_KEY: ${PAYMENT_GATEWAY_KEY}
      PAYMENT_GATEWAY_SECRET: ${PAYMENT_GATEWAY_SECRET}
      KAFKA_BROKER: ${KAFKA_BROKER}
      KAFKA_TOPIC: ${KAFKA_TOPIC}
    networks:
      - default
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: ["air", "-c", ".air.toml"]
    volumes:
      - ./payment-service:/app/payment-service:cached

  # db:
  #   image: postgres:16
  #   env_file:
  #     - ./.env
  #   environment:
  #     POSTGRES_USER: ${POSTGRES_USER}
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #     POSTGRES_DB: ${POSTGRES_DB}
  #   ports:
  #     - "5432:5432"
  # # Infrastructure services (same as production)

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    env_file:
      - ./.env
    environment:
      - discovery.type=${ES_DISCOVERY_TYPE}
      - xpack.security.enabled=${ES_XPACK_SECURITY_ENABLED}
      - "ES_JAVA_OPTS=${ES_JAVA_OPTS}"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    env_file:
      - ./.env
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME}
    networks:
      - default

  kafka:
    # image: confluentinc/cp-kafka:latest
    image: confluentinc/cp-kafka:7.4.3
    container_name: kafka
    ports:
      - "9092:9092"
    env_file:
      - ./.env
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    depends_on:
      - zookeeper
    networks:
      - default

  kafka-setup:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-setup
    depends_on:
      - kafka
    command: >
      bash -c "
        echo -e 'Waiting for Kafka to be ready...' &&
        cub kafka-ready -b ${KAFKA_BROKER} 1 120 &&
        echo -e 'Creating Kafka topics...' &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic payment &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic payment_events &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic payment_requests &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic order_success &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic order_returned &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic vendor_payment_processed &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic vendor_account_updates &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic vendor_payments &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic bank_payouts &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic product-events &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic email-events &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 3 --replication-factor 1 --topic user.created &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic user.created.dlq &&
        kafka-topics --create --if-not-exists --bootstrap-server ${KAFKA_BROKER} --partitions 1 --replication-factor 1 --topic product_rating_updates &&
        echo -e 'Successfully created the following topics:' &&
        kafka-topics --list --bootstrap-server ${KAFKA_BROKER}
      "
    networks:
      - default

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always
    networks:
      - default
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    env_file:
      - ./.env
    environment:
      - REDIS_ADDR=${REDIS_ADDR}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DB}
  # Separate Postgres instances per service (no host port mapping to avoid conflicts)
  postgres-auth:
    image: postgres:16
    container_name: postgres-auth
    restart: always
    environment:
      POSTGRES_USER: ${AUTH_POSTGRES_USER}
      POSTGRES_PASSWORD: ${AUTH_POSTGRES_PASSWORD}
      POSTGRES_DB: ${AUTH_POSTGRES_DB}
    volumes:
      - postgres_auth_data:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres-user:
    image: postgres:16
    container_name: postgres-user
    restart: always
    env_file:
      - ./.env
    environment:
      POSTGRES_USER: ${USER_POSTGRES_USER}
      POSTGRES_PASSWORD: ${USER_POSTGRES_PASSWORD}
      POSTGRES_DB: ${USER_POSTGRES_DB}
    volumes:
      - postgres_user_data:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres-payment:
    image: postgres:16
    container_name: postgres-payment
    restart: always
    env_file:
      - ./.env
    volumes:
      - postgres_payment_data:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres-order:
    image: postgres:16
    container_name: postgres-order
    restart: always
    env_file:
      - ./order-service/.env
    volumes:
      - postgres_order_data:/var/lib/postgresql/data
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    env_file:
      - ./.env
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "5050:80"
    depends_on:
      - postgres-auth
    networks:
      - default
  # Optional: Add api-gateway for development if needed (without Kong)
  # api-gateway:
  #   build:
  #     context: .
  #     dockerfile: ./api-gateway/Dockerfile.dev
  #   ports:
  #     - "8080:8080"
  #   env_file:
  #     - ./api-gateway/.env
  #   volumes:
  #     - ./api-gateway:/app/api-gateway:cached
  #     - ./go.mod:/app/go.mod:ro
  #     - ./go.sum:/app/go.sum:ro
  #   networks:
  #     - default
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

volumes:
  redis_data:
  elasticsearch_data:
  postgres_data:
  postgres_auth_data:
  postgres_payment_data:
  postgres_order_data:
  postgres_user_data:

networks:
  default:
    driver: bridge
